a- [ ] Implement Rust CLI for record. Jenna is working on this.
  - The Rust wrapper should replace the functionality of `record` in the `./probe_py/cli.py`. It should output a language-neutral structure that can be parsed quickly later on.
  - [x] The Rust wrapper should exec the program in an environment with libprobe in `LD_PRELOAD`.
  - [x] The Rust wrapper should transcribe the C structs into a language-neutral format.
  - [x] Split "transcribing" from "running in PROBE". We should be able to do them in two steps.
  - [ ] Parse the language-neutral format into a `ProvLogTree` in Python, replacing `./probe_py/parse_probe_log.py`.
  - [ ] Make sure analysis code still runs.
  - [ ] Get GDB working.
  - [ ] Compile statically.
- [ ] Write end-to-end-tests. End-to-end test should verify properties of the NetworkX graph returned by `provlog_to_digraph`.
  - [ ] Check generic properties (Shofiya is working on this)
    - [ ] The file descriptor used in CloseOp is one returned by a prior OpenOp (or a special file descriptor).
    - [ ] Verify we aren't "missing" an Epoch ID, e.g., 0, 1, 3, 4 is missing 2.
    - [ ] Verify that the TID returned by CloneOp is the same as the TID in the InitOp of the new thread.
    - [ ] Verify that the TID returned by WaitOp is a TID previously returned by CloneOp.
    - [ ] Verify the graph is acyclic and has one root.
    - [ ] Put some of these checks in a function, and have that function be called by `PROBE analysis --check`.
    - Note that the application may not close every file descriptor it opens; that would be considered a "sloppy" application, but it should still work in PROBE.
  - [x] Write a pthreads application for testing purposes (Saleha finished this).
  - [ ] Verify some properties of the pthreads application.
    - [ ] Verify that the main thread has N CloneOp followed by N WaitOps.
  - [ ] Verify some properties of `cp a b`.
    - [ ] Verify that `a` gets opened for reading.
    - [ ] Verify that `b` gets opened for writing.
    - [ ] Verify the file descriptors get closed at some point after both opens.
  - [ ] Verify some properties of `sh -c "cat a ; cat b"`
    - [ ] Verify that the root process has a CloneOp, WaitOp, CloneOp, WaitOp.
    - [ ] Verify that the first child process has ExecOp, OpenOp (path should be `a`), and CloseOp. Analogously check the second child process.
  - [ ] Verify that this doesn't crash `sh -c "sh -c 'cat a ; cat b' ; sh -c 'cat d ; cat e'"` (in the past it did)
  - [ ] Continue along these lines one or two more cases.
- [ ] Link with libbacktrace on `--debug` runs.
- [ ] Write remote script wrappers
  - [ ] Write an SSH wrapper. Asif and Shofiya are working on this.
    - [ ] There should be a shell script named `ssh` that calls `./PROBE ssh <args...>`.
    - [ ] `./PROBE ssh <args...>` will determine which arguments are arguments to SSH and which are arguments to a command, if any. Note that `ssh` can be called with or without a command, e.g., `ssh user@remote command --args` or `ssh user@remote` (user types interactively). In the latter case, we should pretend the command was `$SHELL` in the remote environment, defaulting to bash.
    - [ ] `./PROBE ssh` will then determine the architecture and OS of the remote system. If the architecture and OS does not match the local, we should raise `NotImplementedError` explaining as much.
    - [ ] `./PROBE ssh` should install `libprobe.so` or `libprobe-dbg.so` (depending on a command-line flag), if absent, to the remote at `${XDG_DATA_HOME}`, defaulting to `$HOME/.local/share` if `XDG_DATA_HOME` is unset.
    - [ ] `./PROBE ssh` should create an empty directory on the remote.
    - [ ] `./PROBE ssh` should run `env LD_LIBRARY_PATH=path/to/libprobe.so PROBE_DIR=path/to/blank-dir <command> <args...>` (from earlier) on the remote.
    - [ ] `./PROBE ssh` should tar, gzip, and download the PROBE log directory to the local host for further processing. Assumme for the moment that `tar` and `gzip` exist on the remote. When the Rust wrapper is complete, we can eliminate this dependency.
    - Think about avoiding multiple SSH sessions, and think about assumptions on the remote host.
  - [ ] Write an [SCP wrapper](https://www.wikiwand.com/en/Secure_copy_protocol). The wrapper should be a shell named `scp` that calls `./PROBE scp <args...>`. `./PROBE scp <args...>` should determine whether we are going remote->local or local->remote. It should look for provenance of the inodes of the target files on the "source" node (could be local or remote) in `${XDG_DATA_HOME:$HOME/.local/share}`. It should copy the releveant provenance tree of just those inodes to the "destination node" (either local or remote). Then it should call the "real" `scp` with the appropriate arguments.
  - [ ] Write an [Rsync wrapper](https://rsync.samba.org/), which does the same thing as the SCP wrapper. Use `--dry-run` to determine which files will be accessed.
  - [ ] Research how `mpirun` works and write a wrapper for that.
  - [ ] Research how Condor works and write a wrapper for that.
- [ ] Think about in situ transcription and analysis
  - Think about assumptions in analysis
  - Think about front-end and UI/UX
- [ ] Set up CI
  - [x] Write [Justfiles](https://github.com/casey/just). Each of the following should be a target:
    - [x] Format Nix code with alejandra.
    - [x] Format Python code with Black (please add to `flake.nix`).
    - [x] Check Python code with Ruff (please add to `flake.nix`).
    - [x] Check Python code with Mypy.
    - [x] Run tests on the current machine.
  - [x] Write a CI script that uses Nix to install dependencies and run the Justfiles.
  - [ ] Check (not format) code in Alejandra and Black.
  - [ ] Reformat all Python code in Black.
  - [ ] Figure out why tests don't work.
  - [ ] Run tests in an Ubuntu Docker container.
  - [ ] Run tests in a really old Ubuntu Docker container.
- [ ] Write microbenchmarking
  - [ ] Run performance test-cases in two steps: one with just libprobe record and one with just transcription. (3 new CLI entrypoints, described in comments in CLI.py)
  - [ ] Write interesting performance tests, using `benchmark/workloads.py` as inspiration.
  - [ ] Run the benchmarks with Hyperfine, in Containerexec, in a Python script, storing the result as a CSV.
    - Python script that runs `hyperfine ./PROBE record --no-transcribe` and `hyperfine ./PROBE transcribe` for several tests.
- [ ] Output conversions
  - [ ] From the NetworkX digraph, export (Shofiya is working on this):
    - [ ] A dataflow graph, showing only files, processes, and the flow of information between them. The following rules define when there is an edge:
      1. Data flows from a file to a process if on any thread there is an OpenOp with the flags set to `O_RDWR` or `O_RDONLY`.
      2. Data flows from a process to a process if one process CloneOp's the other.
      3. Data flows from a process to a file if on any thread there is a OpenOp with the flags set to `O_RDWR` or `O_WRONLY`.
    - [ ] [Process Run Crate](https://www.researchobject.org/workflow-run-crate/profiles/process_run_crate/) (Saleha is working on this)
    - [ ] [Common Workflow Language](https://www.commonwl.org/)
      - [ ] Write a test that runs the resulting CWL.
    - [ ] Makefile
      - [ ] Write a test that runs the resulting Makefile.
    - [ ] LLM context prompt
      - Build on the work of Nichole Bufford et al.
- [ ] Consider how to combine provenance from multiple sources
  - [ ] Consider language-level sources like rdtlite
  - [ ] Consider combining across multiple runs of PROBE
  - [ ] Consider combining across multiple hosts
- [ ] Ensuring libprobe works
  - [x] Debug why libprobe doesn't work with Python. Sam fixed this.
  - [x] Debug pthreads not making graph.
  - [x] Debug `createFile.c` crash while trying to `mkdir_and_descend`.
  - [x] Debug `gcc`.
  - [x] Add thread ID and pthread ID to op.
  - [ ] Add Dup ops and debug `bash -c 'head foo > bar'`
  - [ ] Compile Libprobe with static Musl instead of glibc.
  - [ ] Put magic bytes in arena
  - [ ] Unify the Arenas.
  - [ ] Try to break it. Jenna has some input on this.
  - [ ] Add interesting cases to tests.
  - [ ] Add more Ops (see branch add-new-ops)
- [ ] Sort dirents (see branch sort-dirents)
- [ ] Generate a replay package.
  - [ ] Should be activated by a flag: `./PROBE record --with-replay`
  - [ ] Should copy all read files into the probe log.
  - [ ] Should export the PROBE log to the following formats with a CWL script:
    - [ ] [OCI image](https://opencontainers.org/) (runnable with Docker)
      - [ ] Test that executing this image produces the same stdout, stderr, and files for the tests we already have.
    - [ ] Tar-ball intended for chroot
    - [ ] VM image.
      - [ ] Test execution again.
    - [ ] Research ways to speed up the recording phase.
- [ ] UX
  - [ ] Document CLI tool.
  - [ ] Combine Python and Rust CLIs.
  - [ ] Improve the README.
  - [ ] Style output with Rich.
  - [ ] Style output of Rust tool.
- [ ] Package for the following platforms:
  - [ ] It should be obvious how to build libprobe and probe cli (Rust) with Nix from the README.
  - [ ] The repository should be an installable Python package, using the PEP 518 (pyproject.toml). Consider having one Python package with bundled binaries and one without.
  - [ ] PyPI
  - [ ] Nix
  - [ ] Spack
  - [ ] Guix
  - [ ] Docker image (consider whether to publish DockerHub, Quay, GHCR, or somewhere else).
  - [ ] Statically linked, downloadable binary
    - Built in CI on each "release" and downloadable from GitHub.
  - [ ] Changelog
- [ ] Develop user study
  - [ ] Develop protocol for assessing ease-of-use.
  - [ ] Apply for IRB.
  - [ ] Do user study.
- [ ] Submit publication
  - [ ] Have a compelling benchmark
  - [ ] Describe the theory of PROBE (how does it work? what are the limitations?)
  - [ ] Describe the operation of PROBE
  - [ ] Describe the user-study
